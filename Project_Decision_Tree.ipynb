{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preprocessing"
      ],
      "metadata": {
        "id": "sER7jYqvhCFZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bLHwW3_xtAb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "id": "1lVzDWQlY3RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpBGKLVWQBwV"
      },
      "source": [
        "# Import the packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "import os\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx8aReIox2Gi"
      },
      "source": [
        "# load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Datasets/Project/train - train.csv.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Datasets/Project/test - test.csv.csv')\n",
        "\n",
        "#Check number of rows and columns in the dataset\n",
        "print(\"The dataset has %d rows and %d columns.\" % df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n",
        "df_test.describe()"
      ],
      "metadata": {
        "id": "mgL2kdL1iI2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)\n",
        "df_test.head(10)"
      ],
      "metadata": {
        "id": "Ws_lXQyCiqxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding Missing Values**"
      ],
      "metadata": {
        "id": "tAvYgoh-TGJV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Mf-fsdyx7C"
      },
      "source": [
        "missing_values = df[pd.isnull(df).any(axis=1)]\n",
        "missing_values\n",
        "\n",
        "missing_values = df_test[pd.isnull(df_test).any(axis=1)]\n",
        "missing_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing unnecessary columns"
      ],
      "metadata": {
        "id": "-OEe0uv5gxna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop([\"ID\", \"Customer_ID\", \"Month\", \"Name\", \"SSN\"], axis=1)\n",
        "df_test = df_test.drop([\"ID\", \"Customer_ID\", \"Month\", \"Name\", \"SSN\"], axis=1)\n"
      ],
      "metadata": {
        "id": "gD7h6PmLQ3Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "unique_values_per_column = {}\n",
        "\n",
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    unique_values_per_column[column] = unique_values\n",
        "\n",
        "# Display the unique values for each column\n",
        "for column, values in unique_values_per_column.items():\n",
        "    print(f\"Column: {column}\")\n",
        "    print(f\"Unique Values: {values}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "r2MCYumcBNuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[(df['Occupation'] != '_______')]\n",
        "df = df[(df['Credit_Mix'] != '_')]\n",
        "df = df[(df['Payment_of_Min_Amount'] != 'NM')]\n",
        "df = df[(df['Payment_Behaviour'] != '!@9#%8')]\n"
      ],
      "metadata": {
        "id": "n0zvoEysDIFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Category Encoding"
      ],
      "metadata": {
        "id": "Z1UiRUFKg52f"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSkyfYRZ5f9e"
      },
      "source": [
        "# 1 = POOR, 2 = Standard and 3 = GOOD\n",
        "df[\"Credit_Score\"] = df[\"Credit_Score\"].apply(lambda x: 1 if x==\"Poor\" else (2 if x==\"Standard\" else 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSnHH730g8Lc"
      },
      "source": [
        "import category_encoders as ce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9PJkM2sg-T5"
      },
      "source": [
        "encoder = ce.OrdinalEncoder(cols=[\"Occupation\", \"Num_Bank_Accounts\", \"Num_Credit_Card\", \"Num_of_Loan\", \"Type_of_Loan\", \"Num_of_Delayed_Payment\", \"Num_Credit_Inquiries\", \"Credit_Mix\", \"Credit_History_Age\", \"Payment_of_Min_Amount\", \"Payment_Behaviour\"])\n",
        "\n",
        "df = encoder.fit_transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "LBbaPmCLXdLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = ce.OrdinalEncoder(cols=[\"Occupation\",\"Num_Bank_Accounts\", \"Num_Credit_Card\", \"Num_of_Loan\", \"Type_of_Loan\", \"Num_of_Delayed_Payment\", \"Num_Credit_Inquiries\", \"Credit_Mix\", \"Credit_History_Age\", \"Payment_of_Min_Amount\", \"Payment_Behaviour\"])\n",
        "\n",
        "df_test = encoder.fit_transform(df_test)"
      ],
      "metadata": {
        "id": "91UqUt5-gMtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.info()"
      ],
      "metadata": {
        "id": "s-4CwCEMglRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLtvGIDw3KVG"
      },
      "source": [
        "# check missing values in variables\n",
        "\n",
        "df.isnull().sum()\n",
        "print()\n",
        "df_test.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.replace('_', np.nan, inplace=True)\n",
        "df_test.replace('_', np.nan, inplace=True)\n",
        "df = df.apply(pd.to_numeric, errors='coerce')\n",
        "df_test = df_test.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df = df.fillna(df.mean())\n",
        "df_test = df_test.fillna(df_test.mean())"
      ],
      "metadata": {
        "id": "7uj0zAJoyf4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing Outliers"
      ],
      "metadata": {
        "id": "3BS7Z6zqIn9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "# Specify the factor for IQR (e.g., 1.5)\n",
        "iqr_factor = 1.5\n",
        "\n",
        "# Compute the first quartile (Q1) and third quartile (Q3)\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "\n",
        "# Calculate the IQR for each column\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Create a boolean mask for outliers\n",
        "outliers_mask = (df < (Q1 - iqr_factor * IQR)) | (df > (Q3 + iqr_factor * IQR))\n",
        "\n",
        "# Replace outliers with median values column-wise\n",
        "df = df.where(~outliers_mask, df.median(axis=0), axis=1)\n",
        "\n",
        "# Display the resulting DataFrame with outliers replaced by median values\n",
        "print(df)"
      ],
      "metadata": {
        "id": "e2yj4Ds9Ivlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Classifier"
      ],
      "metadata": {
        "id": "BMjM1BM2xKIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CART"
      ],
      "metadata": {
        "id": "_9R9qRsJJWFt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PsBvGTXgoBC"
      },
      "source": [
        "X = df.drop(['Credit_Score'], axis=1)\n",
        "\n",
        "y = df['Credit_Score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NujSBYYdgq7y"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLdkjGwCguBa"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Scaling**"
      ],
      "metadata": {
        "id": "mOYNFk9dc0k9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy7rRVCNhnks"
      },
      "source": [
        "# Find more about scikit-learn's implementation of decision trees here - https://scikit-learn.org/stable/modules/tree.html\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.dtypes)"
      ],
      "metadata": {
        "id": "lcmbpDkofJuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ey8tWm0hp8m"
      },
      "source": [
        "# setting maximum depth of the decision tree to be level 7 with randomly chosen samples in the training set\n",
        "clf_gini = DecisionTreeClassifier(max_depth=7, random_state=42)\n",
        "\n",
        "# fit the model\n",
        "clf_gini.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNc3jbr0htD6"
      },
      "source": [
        "# Getting some predictions from the testing set\n",
        "y_pred_gini = clf_gini.predict(X_test)\n",
        "\n",
        "y_pred_gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuJI01gahvvC"
      },
      "source": [
        "# Finding the testing accuracy of the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Test accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_gini)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1pEGN44hyyu"
      },
      "source": [
        "# Finding the training accuracy of the model\n",
        "y_pred_train_gini = clf_gini.predict(X_train)\n",
        "\n",
        "y_pred_train_gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrTsqNYfh1Ta"
      },
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_gini)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxSJHadfh4l5"
      },
      "source": [
        "# print the scores on training and test set\n",
        "\n",
        "print('Training set score: {:.4f}'.format(clf_gini.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(clf_gini.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neXC2N-Qh9Cc"
      },
      "source": [
        "# plotting the splits\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(96,48))\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "tree.plot_tree(clf_gini.fit(X_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u3-oc5niFNU"
      },
      "source": [
        "import graphviz\n",
        "dot_data = tree.export_graphviz(clf_gini, out_file=None,\n",
        "                              feature_names=X_train.columns,\n",
        "                              class_names=str(y_train),\n",
        "                              filled=True, rounded=True,\n",
        "                              special_characters=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "\n",
        "graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEhJpYRw7UD0"
      },
      "source": [
        "# Save the figure for future reference\n",
        "graph.render(filename='cart',directory='/content/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model"
      ],
      "metadata": {
        "id": "FNCrN4cPLnEl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgrxhmlFik3k"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_gini)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OOJh-Abvrnd"
      },
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_gini.classes_)\n",
        "disp.plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhspVgm8ip6-"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_gini))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting the values of the testing set"
      ],
      "metadata": {
        "id": "Ue0zkj_yO7I_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl6dYIelPDe4"
      },
      "source": [
        "# Getting some predictions from the testing set\n",
        "y_pred_gini = clf_gini.predict(df_test)\n",
        "\n",
        "y_pred_gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C4.5"
      ],
      "metadata": {
        "id": "0DdpKcIOn2O5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cEHCFVuiL6M"
      },
      "source": [
        "# setting maximum depth of the decision tree to be level 3 with randomly chosen samples in the training set\n",
        "clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=12, random_state=42)\n",
        "\n",
        "# fit the model\n",
        "clf_en.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xedELIHiPKZ"
      },
      "source": [
        "# Getting some predictions from the testing set\n",
        "y_pred_en = clf_en.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLUbMDniRGw"
      },
      "source": [
        "# Getting some predictions from the training set\n",
        "y_pred_train_en = clf_en.predict(X_train)\n",
        "\n",
        "y_pred_train_en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgLSyikWiTl5"
      },
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_en)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr54M6S7iVsU"
      },
      "source": [
        "print('Training set score: {:.4f}'.format(clf_en.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(clf_en.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuJSoCdoiY1Y"
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "tree.plot_tree(clf_en.fit(X_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSKaZlw7icoW"
      },
      "source": [
        "import graphviz\n",
        "dot_data = tree.export_graphviz(clf_en, out_file=None,\n",
        "                              feature_names=X_train.columns,\n",
        "                              class_names=str(y_train),\n",
        "                              filled=True, rounded=True,\n",
        "                              special_characters=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "\n",
        "graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbbF4dD_8WqZ"
      },
      "source": [
        "# Save the figure for future reference\n",
        "graph.render(filename='C4.5.dot',directory='/content/drive/MyDrive/Colab Notebooks/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGdU3XC2x_s4"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_en)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWPYQqZAx_s5"
      },
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_gini.classes_)\n",
        "disp.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMfstZJ2x_s6"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_en))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o63XNp741GWl"
      },
      "source": [
        "# Getting some predictions from the training set\n",
        "y_pred_train_en = clf_en.predict(df_test)\n",
        "\n",
        "y_pred_train_en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_df_test = df_test.copy()"
      ],
      "metadata": {
        "id": "l62Dfrnn1Om8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_df_test[\"Credit_Score\"] = y_pred_train_en"
      ],
      "metadata": {
        "id": "TQw-X7xq1Uk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_df_test.head(10)"
      ],
      "metadata": {
        "id": "HWieAriQ1fBP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}